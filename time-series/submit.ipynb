{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Record:\n",
      "20000\n",
      "\n",
      "\n",
      "is nan : \n",
      " Date Time    0\n",
      "T (degC)     0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "is null : \n",
      " Date Time    0\n",
      "T (degC)     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>T (degC)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2009 00:10:00</td>\n",
       "      <td>-8.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2009 00:20:00</td>\n",
       "      <td>-8.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2009 00:30:00</td>\n",
       "      <td>-8.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2009 00:40:00</td>\n",
       "      <td>-8.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2009 00:50:00</td>\n",
       "      <td>-8.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>19.05.2009 20:40:00</td>\n",
       "      <td>16.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>19.05.2009 20:50:00</td>\n",
       "      <td>16.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>19.05.2009 21:00:00</td>\n",
       "      <td>15.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>19.05.2009 21:10:00</td>\n",
       "      <td>16.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>19.05.2009 21:20:00</td>\n",
       "      <td>15.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date Time  T (degC)\n",
       "0      01.01.2009 00:10:00     -8.02\n",
       "1      01.01.2009 00:20:00     -8.41\n",
       "2      01.01.2009 00:30:00     -8.51\n",
       "3      01.01.2009 00:40:00     -8.31\n",
       "4      01.01.2009 00:50:00     -8.27\n",
       "...                    ...       ...\n",
       "19995  19.05.2009 20:40:00     16.51\n",
       "19996  19.05.2009 20:50:00     16.19\n",
       "19997  19.05.2009 21:00:00     15.88\n",
       "19998  19.05.2009 21:10:00     16.05\n",
       "19999  19.05.2009 21:20:00     15.78\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./jena_climate_2009_2016.csv')\n",
    "total_null = dataset.isnull().sum().sort_values(ascending=False)\n",
    "dataset = dataset[:20000]\n",
    "newset = dataset[['Date Time','T (degC)']]\n",
    "print(\"\")\n",
    "print(\"Total Record:\")\n",
    "print(dataset.shape[0])\n",
    "print(\"\\n\")\n",
    "print(\"is nan : \\n\",newset.isna().sum())\n",
    "print(\"\\n\")\n",
    "print(\"is null : \\n\",newset.isnull().sum())\n",
    "newset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
    "    # series = tf.expand_dims(series, axis=-1)\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w[:-1], w[-1:]))\n",
    "    return ds.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "dates = newset['Date Time'].values\n",
    "temp  = newset['T (degC)'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='mae',\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    min_delta=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "160/160 [==============================] - 6s 29ms/step - loss: 0.0024 - mae: 0.0475\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 5s 29ms/step - loss: 3.8132e-04 - mae: 0.0204\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 5s 29ms/step - loss: 2.0960e-04 - mae: 0.0146\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 5s 29ms/step - loss: 1.7467e-04 - mae: 0.0131\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 5s 30ms/step - loss: 1.5875e-04 - mae: 0.0125\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 5s 30ms/step - loss: 1.4971e-04 - mae: 0.0122\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 5s 29ms/step - loss: 1.3956e-04 - mae: 0.0116\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 5s 29ms/step - loss: 1.3433e-04 - mae: 0.0114\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 5s 29ms/step - loss: 1.2847e-04 - mae: 0.0111\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 5s 29ms/step - loss: 1.1850e-04 - mae: 0.0107\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 5s 31ms/step - loss: 1.1128e-04 - mae: 0.0103\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "temp_train, temp_test, dates_train, dates_test = train_test_split(\n",
    "    temp, dates, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Apply Min-Max Scaling to 'T (degC)'\n",
    "scaler = MinMaxScaler()\n",
    "temp_scaled = scaler.fit_transform(temp_train.reshape(-1, 1))\n",
    "\n",
    "train_set = windowed_dataset(\n",
    "    temp_scaled, window_size=60, batch_size=100, shuffle_buffer=1000)\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64),\n",
    "        merge_mode='concat',\n",
    "    ),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=0.2, momentum=0.5)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "history = model.fit(train_set, epochs=100,callbacks=[early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
